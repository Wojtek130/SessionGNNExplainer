{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import model\n",
    "import TAGNNWrapper\n",
    "import SessionExplainer\n",
    "import tagnn_yoochoose\n",
    "\n",
    "importlib.reload(model)\n",
    "importlib.reload(TAGNNWrapper)\n",
    "importlib.reload(SessionExplainer)\n",
    "importlib.reload(tagnn_yoochoose)\n",
    "\n",
    "\n",
    "from utils import Data\n",
    "from SessionExplainer import SessionExplainer\n",
    "from TAGNNWrapper import TAGNNWrapper\n",
    "from tagnn_yoochoose import tagnn\n",
    "from model import trans_to_cuda\n",
    "from analysis_utils import initialize_file, close_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"sessions_data/\"\n",
    "\n",
    "session_data = [ os.path.join(directory, filename) for filename in os.listdir(directory) if filename.endswith(\".pt\") or filename.endswith(\".pth\")]\n",
    "len(session_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ranking = torch.load('vertex_ranking.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_explanation(session, file_path, epochs = 2000, k = 10, modify_global_embedding = False, shortened = False):\n",
    "    se = SessionExplainer(tagnn, session, epochs = epochs)\n",
    "    x = trans_to_cuda(torch.ones(se.tagnn_wrapper.tagnn.n_node - 1))\n",
    "    x = x.unsqueeze(1)\n",
    "    targets = se.tagnn.compute_scores(se.session_data[\"seq_hidden\"], se.session_data[\"mask\"], x, None, None, False)\n",
    "    target = torch.argmax(torch.nn.functional.softmax(targets[0], dim=0)).item()\n",
    "    e = se.explain(session[-1], modify_global_embedding = modify_global_embedding)\n",
    "    values, indices = torch.sort(e.node_mask.squeeze(-1), descending=True)\n",
    "    best_non_target_idx, best_non_target_value = ((indices[0], values[0]) if indices[0] != target else (indices[1], values[1]))\n",
    "    ranking_idx = torch.nonzero(vertex_ranking[:, 1] == best_non_target_idx, as_tuple=True)[0]\n",
    "    ranking_value = vertex_ranking[ranking_idx, 0]\n",
    "    data = {\n",
    "        \"session\": session,\n",
    "        \"shortened\": shortened,\n",
    "        \"modify_global_embedding\": modify_global_embedding,\n",
    "        \"max\": e.node_mask.max().item(),\n",
    "        \"min\": e.node_mask.min().item(),\n",
    "        \"mean\": e.node_mask.mean().item(),\n",
    "        \"target\": target,\n",
    "        \"best_vertex\" : {\n",
    "            \"id\": best_non_target_idx.item(),\n",
    "            \"value\": best_non_target_value.item(),\n",
    "            \"ranking_position\": ranking_idx.item(),\n",
    "            \"ranking_value\": ranking_value.item(),\n",
    "            \"in_session\": best_non_target_idx in session,\n",
    "        },\n",
    "        \"values\": values.tolist()[:k],\n",
    "        \"indices\": indices.tolist()[:k],\n",
    "    }\n",
    "    with open(file_path, 'a') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "        if not shortened or not modify_global_embedding:\n",
    "            json_file.write(',')\n",
    "        json_file.write('\\n')\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"explanation_files_long_training_rerun/\"\n",
    "k = 100\n",
    "epochs = 12000\n",
    "for i, filename in enumerate(session_data):\n",
    "    sessions = []\n",
    "    sessions_batch = torch.load(filename)\n",
    "    dim = sessions_batch[\"mask\"].shape[0]\n",
    "    for i in range(dim):\n",
    "        session_data = {key: value[i].unsqueeze(0) for key, value in sessions_batch.items()}\n",
    "        session = torch.gather(session_data[\"items\"], 1, session_data[\"alias_inputs\"]).squeeze()[:session_data[\"mask\"].sum()].tolist()\n",
    "        if len(session) >= 5:\n",
    "            sessions.append(session)\n",
    "    m = re.search(r\"batch_(\\d+)\\.pt\", filename)\n",
    "    batch_no = int(m.group(1)) if m else 0\n",
    "    if any(f\"b{str(batch_no)}\" in f for f in os.listdir(dir) if os.path.isfile(os.path.join(dir, f))):\n",
    "        print(f\"Batch {batch_no} already processed. Skipping...\")\n",
    "        continue\n",
    "    print(f\"Processing batch {batch_no} with {len(sessions)} sessions; {i} / {len(session_data)}\")\n",
    "    for j, s in enumerate(sessions):\n",
    "        file_path = os.path.join(dir, f\"explanation_b{batch_no}_s{j}.json\")\n",
    "        initialize_file(file_path)\n",
    "        for modify_global_embedding in [True, False]:\n",
    "            start_time = time.time()\n",
    "            generate_and_save_explanation(s, file_path, modify_global_embedding = modify_global_embedding, epochs=epochs, k=k)\n",
    "            generate_and_save_explanation(s, file_path, modify_global_embedding = modify_global_embedding, epochs=epochs, k=k)\n",
    "            generate_and_save_explanation(s[1:], file_path, modify_global_embedding = modify_global_embedding, shortened = True, epochs=epochs, k=k)\n",
    "            end_time = time.time()\n",
    "            print(\"Processing time:\", end_time - start_time)\n",
    "        close_file(file_path)\n",
    "        print(f\"{i}/{len(session_data)}\")\n",
    "\n",
    "    print(batch_no)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research2025",
   "language": "python",
   "name": "research2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
