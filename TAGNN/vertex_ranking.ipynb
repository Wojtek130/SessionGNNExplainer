{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import namedtuple\n",
    "import gzip\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from model import SessionGraph, forward, trans_to_cuda, trans_to_cpu\n",
    "from utils import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_matrix(filename_tagnn_input_data = '../YooChoose 1_64 Dataset Preparation/ziob_yoochoose_1_64n.pcklz', number_of_nodes = -1, batch_size = 32, training_epochs = 50):\n",
    "    with gzip.open(filename_tagnn_input_data, 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "        test_data = pickle.load(f)\n",
    "        pids = pickle.load(f)\n",
    "\n",
    "    if number_of_nodes == -1:\n",
    "        number_of_nodes = len(pids)\n",
    "    print(number_of_nodes)\n",
    "    vertex_ranking = np.zeros((number_of_nodes))\n",
    "    train_data = Data(train_data, shuffle=True)\n",
    "    c = 0\n",
    "    e = 0\n",
    "    print(f\"len(slices): {len(train_data.generate_batch(batch_size))}, no : {number_of_nodes}\")\n",
    "    slices = train_data.generate_batch(batch_size)\n",
    "    for i, j in zip(slices, np.arange(len(slices))):\n",
    "        if c % 100 == 0 and c != 0:\n",
    "            print(f\"{c}/{len(slices)}\")\n",
    "        alias_inputs, A, items, mask, targets = train_data.get_slice(i)\n",
    "        alias_inputs = trans_to_cuda(torch.Tensor(alias_inputs).long())\n",
    "        items = trans_to_cuda(torch.Tensor(items).long())\n",
    "        A = trans_to_cuda(torch.Tensor(np.array(A)).float())\n",
    "        mask = trans_to_cuda(torch.Tensor(mask).long())\n",
    "        for k in range(batch_size):\n",
    "            if k > mask.shape[0] - 1:\n",
    "                break\n",
    "            for l in range(mask[k].sum().item()):\n",
    "                    try:\n",
    "                        vertex_ranking[items[k][alias_inputs[k]][l].item()] += 1\n",
    "                    except:\n",
    "                        print(f\"k: {k}, l: {l}\")\n",
    "                        e += 1\n",
    "        c += 1\n",
    "    print(f\"errors: {e}\")\n",
    "    return vertex_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16191\n",
      "len(slices): 11520, no : 16191\n",
      "100/11520\n",
      "200/11520\n",
      "300/11520\n",
      "400/11520\n",
      "500/11520\n",
      "600/11520\n",
      "700/11520\n",
      "800/11520\n",
      "900/11520\n",
      "1000/11520\n",
      "1100/11520\n",
      "1200/11520\n",
      "1300/11520\n",
      "1400/11520\n",
      "1500/11520\n",
      "1600/11520\n",
      "1700/11520\n",
      "1800/11520\n",
      "1900/11520\n",
      "2000/11520\n",
      "2100/11520\n",
      "2200/11520\n",
      "2300/11520\n",
      "2400/11520\n",
      "2500/11520\n",
      "2600/11520\n",
      "2700/11520\n",
      "2800/11520\n",
      "2900/11520\n",
      "3000/11520\n",
      "3100/11520\n",
      "3200/11520\n",
      "3300/11520\n",
      "3400/11520\n",
      "3500/11520\n",
      "3600/11520\n",
      "3700/11520\n",
      "3800/11520\n",
      "3900/11520\n",
      "4000/11520\n",
      "4100/11520\n",
      "4200/11520\n",
      "4300/11520\n",
      "4400/11520\n",
      "4500/11520\n",
      "4600/11520\n",
      "4700/11520\n",
      "4800/11520\n",
      "4900/11520\n",
      "5000/11520\n",
      "5100/11520\n",
      "5200/11520\n",
      "5300/11520\n",
      "5400/11520\n",
      "5500/11520\n",
      "5600/11520\n",
      "5700/11520\n",
      "5800/11520\n",
      "5900/11520\n",
      "6000/11520\n",
      "6100/11520\n",
      "6200/11520\n",
      "6300/11520\n",
      "6400/11520\n",
      "6500/11520\n",
      "6600/11520\n",
      "6700/11520\n",
      "6800/11520\n",
      "6900/11520\n",
      "7000/11520\n",
      "7100/11520\n",
      "7200/11520\n",
      "7300/11520\n",
      "7400/11520\n",
      "7500/11520\n",
      "7600/11520\n",
      "7700/11520\n",
      "7800/11520\n",
      "7900/11520\n",
      "8000/11520\n",
      "8100/11520\n",
      "8200/11520\n",
      "8300/11520\n",
      "8400/11520\n",
      "8500/11520\n",
      "8600/11520\n",
      "8700/11520\n",
      "8800/11520\n",
      "8900/11520\n",
      "9000/11520\n",
      "9100/11520\n",
      "9200/11520\n",
      "9300/11520\n",
      "9400/11520\n",
      "9500/11520\n",
      "9600/11520\n",
      "9700/11520\n",
      "9800/11520\n",
      "9900/11520\n",
      "10000/11520\n",
      "10100/11520\n",
      "10200/11520\n",
      "10300/11520\n",
      "10400/11520\n",
      "10500/11520\n",
      "10600/11520\n",
      "10700/11520\n",
      "10800/11520\n",
      "10900/11520\n",
      "11000/11520\n",
      "11100/11520\n",
      "11200/11520\n",
      "11300/11520\n",
      "11400/11520\n",
      "11500/11520\n",
      "errors: 0\n"
     ]
    }
   ],
   "source": [
    "vertex_ranking = get_bigram_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ranking, indices = torch.sort(trans_to_cuda(torch.Tensor(vertex_ranking)), descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16191])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ranking.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15593., 14333., 14253.,  ...,     0.,     0.,     0.], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tensor = torch.stack((sorted_ranking, indices), dim=1)\n",
    "torch.save(merged_tensor, 'vertex_ranking.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research2025",
   "language": "python",
   "name": "research2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
